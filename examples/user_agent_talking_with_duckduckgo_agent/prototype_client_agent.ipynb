{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pocketflow_a2a.a2a_common.client import A2AClient\n",
    "from pocketflow_a2a.a2a_common.types import (\n",
    "    AgentCard,\n",
    "    A2AClientJSONError,\n",
    "    A2AClientHTTPError,\n",
    ")\n",
    "\n",
    "\n",
    "client = A2AClient(url=\"http://localhost:10003\")\n",
    "\n",
    "\n",
    "agent_card = await client.get_agent_card()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PocketFlow Research Agent (A2A Wrapped)\n",
      "Web Research and Answering\n",
      "Answers questions using web search results when necessary.\n",
      "['text', 'text/plain']\n",
      "['text', 'text/plain']\n",
      "['Who won the Nobel Prize in Physics 2024?', 'What is quantum computing?', 'Summarize the latest news about AI.']\n",
      "['research', 'qa', 'web search']\n",
      "web_research_qa\n",
      "Web Research and Answering\n"
     ]
    }
   ],
   "source": [
    "print(agent_card.name)\n",
    "for skill in agent_card.skills:\n",
    "    print(skill.name)\n",
    "    print(skill.description)\n",
    "    print(skill.inputModes)\n",
    "    print(skill.outputModes)\n",
    "    print(skill.examples)\n",
    "    print(skill.tags)\n",
    "    print(skill.id)\n",
    "    print(skill.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get available agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are agents who can you ask for consult:\n",
      "\n",
      "Available agents:\n",
      "\n",
      "Agent number 1:\n",
      "Name: PocketFlow Research Agent (A2A Wrapped)\n",
      "Description: A simple research agent based on PocketFlow, made accessible via A2A.\n",
      "Skills: \n",
      "    - name: Web Research and Answering\n",
      "        - description: Answers questions using web search results when necessary.\n",
      "        - example: ['Who won the Nobel Prize in Physics 2024?', 'What is quantum computing?', 'Summarize the latest news about AI.']\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "You may select one of them to help answer by return the array of selected agent number or if you find no one could help you, you may return empty array.\n",
      "Your answer will be passed directly to JSON so You must return your selected agent(s) with the following JSON fiedls\n",
      "[\n",
      "    {\n",
      "        \"selected_agent: <int, the number of agent that you choose to answer this question>,\n",
      "        \"question_to_answer\": <str, the question to ask the agent>\n",
      "    },\n",
      "    {/*...other agent you can select as much as you want*/}\n",
      "]\n",
      "\n",
      "Remember: Your answer will be passed directly to JSON parsing function, therefore return only the array of json and not include PREFIX, SUFFIX or Prologue\n"
     ]
    }
   ],
   "source": [
    "from pocketflow import AsyncFlow, AsyncNode\n",
    "from typing import TypedDict\n",
    "import asyncio\n",
    "from a2a_client.prompt_templates import available_agents_template\n",
    "from a2a_client.types import Shared, SelectedAgent\n",
    "\n",
    "\n",
    "class GetAvailableAgentsNode(AsyncNode):\n",
    "    async def prep_async(self, shared):\n",
    "        a2a_clients = shared[\"a2a_clients\"]\n",
    "        return a2a_clients\n",
    "\n",
    "    async def exec_async(self, a2a_clients: list[A2AClient]):\n",
    "        return await asyncio.gather(\n",
    "            *[a2a_client.get_agent_card() for a2a_client in a2a_clients]\n",
    "        )\n",
    "\n",
    "    async def exec_fallback_async(self, prep_res, exc):\n",
    "        raise exc\n",
    "\n",
    "    async def post_async(\n",
    "        self,\n",
    "        shared,\n",
    "        prep_res,\n",
    "        exec_res: list[AgentCard | A2AClientJSONError | A2AClientHTTPError],\n",
    "    ) -> str:\n",
    "        agents_list = [res for res in exec_res if isinstance(res, AgentCard)]\n",
    "        if not agents_list:\n",
    "            shared[\"agents_list\"] = []\n",
    "            shared[\"available_agents_prompt\"] = None\n",
    "        else:\n",
    "            shared[\"agents_list\"] = agents_list\n",
    "            shared[\"available_agents_prompt\"] = available_agents_template.render(\n",
    "                agents=[agent.model_dump() for agent in agents_list]\n",
    "            )\n",
    "        return \"agent_selector\"\n",
    "\n",
    "\n",
    "get_available_agents_node = GetAvailableAgentsNode()\n",
    "\n",
    "flow = AsyncFlow(start=get_available_agents_node)\n",
    "shared = {\"a2a_clients\": [A2AClient(url=\"http://localhost:10003\")]}\n",
    "await flow.run_async(shared)\n",
    "print(shared[\"available_agents_prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2a_client.utils import call_llm\n",
    "from a2a_client.prompt_templates import agent_selector_template\n",
    "from typing import cast\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "def parse_json_string(s: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parse a string containing JSON (optionally wrapped in markdown code block) into a Python dictionary.\n",
    "    \"\"\"\n",
    "    # Remove leading/trailing whitespace\n",
    "    s = s.strip()\n",
    "    # Remove markdown code block if present\n",
    "    # Handles ```json ... ``` or ``` ... ```\n",
    "    code_block_pattern = r\"^```(?:json)?\\s*([\\s\\S]*?)\\s*```$\"\n",
    "    match = re.match(code_block_pattern, s, re.IGNORECASE)\n",
    "    if match:\n",
    "        s = match.group(1).strip()\n",
    "    # Now parse as JSON\n",
    "    return json.loads(s)\n",
    "\n",
    "\n",
    "class AgentSelectorNode(AsyncNode):\n",
    "    async def prep_async(self, shared):\n",
    "        return (shared[\"question\"], shared[\"available_agents_prompt\"])\n",
    "\n",
    "    async def exec_async(self, inputs):\n",
    "        question, available_agents_prompt = inputs\n",
    "        prompt = agent_selector_template.render(\n",
    "            question=question, available_agents_prompt=available_agents_prompt\n",
    "        )\n",
    "        return call_llm(prompt)\n",
    "\n",
    "    async def post_async(self, shared, prep_res, exec_res):\n",
    "        shared[\"selected_agents\"] = cast(\n",
    "            list[SelectedAgent], parse_json_string(exec_res)\n",
    "        )\n",
    "        if shared[\"selected_agents\"]:\n",
    "            return \"execute_agent\"\n",
    "        else:\n",
    "            return \"answer_with_no_context\"\n",
    "\n",
    "\n",
    "get_available_agents_node = GetAvailableAgentsNode()\n",
    "agent_selector_node = AgentSelectorNode()\n",
    "\n",
    "get_available_agents_node - \"agent_selector\" >> agent_selector_node\n",
    "\n",
    "flow = AsyncFlow(start=get_available_agents_node)\n",
    "\n",
    "shared = {\n",
    "    \"question\": \"Who won the Nobel Prize in Physics 2024?\",\n",
    "    \"a2a_clients\": [A2AClient(url=\"http://localhost:10003\")],\n",
    "}\n",
    "await flow.run_async(shared)\n",
    "\n",
    "print(shared[\"selected_agents\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'action'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "from pocketflow_a2a.a2a_common.types import SendTaskResponse\n",
    "from a2a_client.prompt_templates import action_template, agent_context_template\n",
    "from a2a_client.types import Payload, AgentContext\n",
    "\n",
    "\n",
    "\n",
    "def construct_payload(task_id: str, session_id: str, question: str):\n",
    "    payload = {\n",
    "        \"id\": task_id,\n",
    "        \"sessionId\": session_id,\n",
    "        \"message\": {\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": [\n",
    "                {\n",
    "                    \"type\": \"text\",  # Explicitly match TextPart structure\n",
    "                    \"text\": question,\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        \"acceptedOutputModes\": [\"text\", \"text/plain\"],  # What the client wants back\n",
    "    }\n",
    "    return payload\n",
    "\n",
    "\n",
    "class ExecuteAgentNode(AsyncNode):\n",
    "    async def prep_async(self, shared: Shared) -> list[tuple[Payload, AgentCard]]:\n",
    "        selected_agents = shared[\"selected_agents\"]\n",
    "        agents_list = shared[\"agents_list\"]\n",
    "        session_id = uuid4().hex\n",
    "        payloads_and_agents = [\n",
    "            (\n",
    "                construct_payload(\n",
    "                    uuid4().hex, session_id, selected_agent[\"question_to_answer\"]\n",
    "                ),\n",
    "                agents_list[selected_agent[\"selected_agent\"] - 1],\n",
    "            )\n",
    "            for selected_agent in selected_agents\n",
    "        ]\n",
    "        shared[\"payloads_and_agents\"] = payloads_and_agents\n",
    "        return payloads_and_agents\n",
    "\n",
    "    async def exec_async(\n",
    "        self, payloads_and_agents: list[tuple[Payload, AgentCard]]\n",
    "    ) -> list[tuple[tuple[Payload, AgentCard], SendTaskResponse]]:\n",
    "        responses = await asyncio.gather(\n",
    "            *[\n",
    "                A2AClient(agent_card=agent_card).send_task(payload)\n",
    "                for payload, agent_card in payloads_and_agents\n",
    "            ]\n",
    "        )\n",
    "        return list(zip(payloads_and_agents, responses))\n",
    "\n",
    "    async def exec_fallback_async(self, prep_res, exc):\n",
    "        raise exc\n",
    "\n",
    "    async def post_async(\n",
    "        self,\n",
    "        shared,\n",
    "        prep_res: list[tuple[Payload, AgentCard]],\n",
    "        exec_res: list[tuple[tuple[Payload, AgentCard], SendTaskResponse]],\n",
    "    ):\n",
    "        agent_contexts = []\n",
    "        for (payload, agent_card), response in exec_res:\n",
    "            if response.error:\n",
    "                continue\n",
    "            else:\n",
    "                agent_contexts.append(AgentContext(\n",
    "                    agent_name=agent_card.name,\n",
    "                    agent_skills=[skill.model_dump() for skill in agent_card.skills],\n",
    "                    question=payload[\"message\"][\"parts\"][0][\"text\"],\n",
    "                    answer=response.result.artifacts[-1].parts[0].text\n",
    "                ))\n",
    "                shared[\"artifacts\"] = response.result.artifacts\n",
    "        shared[\"agent_contexts\"] = agent_contexts\n",
    "        if agent_contexts:\n",
    "            shared[\"agent_contexts_prompt\"] = agent_context_template.render(\n",
    "                agent_contexts=agent_contexts\n",
    "            )\n",
    "            return \"action\"\n",
    "        else:\n",
    "            shared[\"agent_contexts_prompt\"] = None\n",
    "            return \"answer_with_no_context\"\n",
    "        \n",
    "\n",
    "\n",
    "execute_agent_node = ExecuteAgentNode()\n",
    "\n",
    "await execute_agent_node.run_async(shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Nobel Prize in Physics for 2024 has not yet been awarded.  The announcement is typically made in October.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from a2a_client.prompt_templates import answer_question_with_no_context_template\n",
    "\n",
    "\n",
    "class AnswerWithNoContextNode(AsyncNode):\n",
    "    async def prep_async(self, shared: Shared) -> str:\n",
    "        prompt = answer_question_with_no_context_template.render(\n",
    "            question=shared[\"question\"],\n",
    "        )\n",
    "        return prompt\n",
    "\n",
    "    async def exec_async(self, prompt: str) -> str:\n",
    "        return call_llm(prompt)\n",
    "\n",
    "    async def post_async(self, shared: Shared, prep_res: str, exec_res: str) -> str:\n",
    "        shared[\"answer\"] = exec_res\n",
    "        return \"done\"\n",
    "\n",
    "\n",
    "answer_with_no_context_node = AnswerWithNoContextNode()\n",
    "\n",
    "answer_with_no_context_node_res = await answer_with_no_context_node.run_async(shared)\n",
    "print(shared[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Hopfield and Geoffrey Hinton won the 2024 Nobel Prize in Physics.\n"
     ]
    }
   ],
   "source": [
    "from a2a_client.prompt_templates import action_template\n",
    "\n",
    "import re\n",
    "import json\n",
    "\n",
    "\n",
    "class ActionNode(AsyncNode):\n",
    "    @staticmethod\n",
    "    def extract_metadata_and_answer(text):\n",
    "        # Extract JSON metadata block\n",
    "        metadata_match = re.search(\n",
    "            r'# metadata\\s*```json\\s*({.*?})\\s*```', text, re.DOTALL)\n",
    "        metadata = None\n",
    "        if metadata_match:\n",
    "            metadata_str = metadata_match.group(1)\n",
    "            metadata = json.loads(metadata_str)\n",
    "        \n",
    "        # Extract answer block\n",
    "        answer_match = re.search(\n",
    "            r'# answer\\s*(.*?)={5,}', text, re.DOTALL)\n",
    "        answer = None\n",
    "        if answer_match:\n",
    "            answer = answer_match.group(1).strip()\n",
    "        \n",
    "        return metadata, answer\n",
    "\n",
    "    async def prep_async(self, shared: Shared) -> str:\n",
    "        action_prompt = action_template.render(\n",
    "            question=shared[\"question\"],\n",
    "            context=shared[\"agent_contexts_prompt\"]\n",
    "        )\n",
    "        return action_prompt\n",
    "\n",
    "    async def exec_async(self, action_prompt: str) -> str:\n",
    "        return call_llm(action_prompt)\n",
    "    \n",
    "    async def post_async(self, shared: Shared, prep_res: str, exec_res: str) -> str:\n",
    "        metadata, answer = self.extract_metadata_and_answer(exec_res)\n",
    "        shared[\"answer\"] = answer\n",
    "        shared[\"answer_metadata\"] = metadata\n",
    "        is_information_enough_to_answer = metadata[\"is_information_enough_to_answer\"]\n",
    "        if is_information_enough_to_answer:\n",
    "            return \"done\"\n",
    "        else:\n",
    "            return \"select_agent\"\n",
    "\n",
    "action_node = ActionNode()\n",
    "\n",
    "action_node_res = await action_node.run_async(shared)\n",
    "print(shared[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoneNode(AsyncNode):\n",
    "    async def prep_async(self, shared: Shared) -> str:\n",
    "        return \"done\"\n",
    "\n",
    "    async def exec_async(self, shared: Shared) -> str:\n",
    "        return \"done\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John J. Hopfield and Geoffrey Hinton won the 2024 Nobel Prize in Physics.\n"
     ]
    }
   ],
   "source": [
    "get_available_agents_node = GetAvailableAgentsNode()\n",
    "agent_selector_node = AgentSelectorNode()\n",
    "execute_agent_node = ExecuteAgentNode()\n",
    "answer_with_no_context_node = AnswerWithNoContextNode()\n",
    "action_node = ActionNode()\n",
    "done_node = DoneNode()\n",
    "\n",
    "\n",
    "get_available_agents_node - \"agent_selector\" >> agent_selector_node\n",
    "get_available_agents_node - \"answer_with_no_context\" >> answer_with_no_context_node\n",
    "\n",
    "# Select agent\n",
    "agent_selector_node - \"execute_agent\" >> execute_agent_node\n",
    "agent_selector_node - \"answer_with_no_context\" >> answer_with_no_context_node\n",
    "\n",
    "# Execute agent\n",
    "execute_agent_node - \"action\" >> action_node\n",
    "execute_agent_node - \"answer_with_no_context\" >> answer_with_no_context_node\n",
    "\n",
    "# Action\n",
    "action_node - \"done\" >> done_node\n",
    "action_node - \"select_agent\" >> agent_selector_node\n",
    "\n",
    "flow = AsyncFlow(start=get_available_agents_node)\n",
    "\n",
    "shared = {\n",
    "    \"question\": \"Who won the Nobel Prize in Physics 2024?\",\n",
    "    \"a2a_clients\": [A2AClient(url=\"http://localhost:10003\")],\n",
    "}\n",
    "await flow.run_async(shared)\n",
    "\n",
    "print(shared[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = await asyncio.gather(\n",
    "    *[\n",
    "        A2AClient(agent_card=agent_card).send_task(payload)\n",
    "        for payload, agent_card in payloads_and_agents\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = responses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await shared[\"a2a_clients\"][0].send_task(payloads_and_agents[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SendTaskResponse(jsonrpc='2.0', id='547353e0b7a84ed3baf955e70ec85f74', result=Task(id='8f9aab968fbe434bb062599a3cbfb761', sessionId='bb5a7d3623354e4ea7029c369b404940', status=TaskStatus(state=<TaskState.COMPLETED: 'completed'>, message=None, timestamp=datetime.datetime(2025, 5, 3, 22, 59, 8, 64534)), artifacts=[Artifact(name=None, description=None, parts=[TextPart(type='text', text='Based solely on the provided research, which names John J. Hopfield and Geoffrey Hinton,  we cannot definitively say who won the Nobel Prize in Physics 2024.  The research only lists two names, and there is no information connecting them to the 2024 Nobel Prize in Physics.  Further information is needed to answer the question.\\n', metadata=None)], metadata=None, index=0, append=None, lastChunk=None)], history=[], metadata=None), error=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': '6d915e4ace574c96bbcb9e697feed1b4',\n",
       "  'sessionId': 'b09b544ce90d4259a4cfc2ad9a76319f',\n",
       "  'message': {'role': 'user',\n",
       "   'parts': [{'type': 'text',\n",
       "     'text': 'How is the Thai stock market performing this week?'}]},\n",
       "  'acceptedOutputModes': ['text', 'text/plain']},\n",
       " AgentCard(name='PocketFlow Research Agent (A2A Wrapped)', description='A simple research agent based on PocketFlow, made accessible via A2A.', url='http://localhost:10003/', provider=None, version='0.1.0-a2a', documentationUrl=None, capabilities=AgentCapabilities(streaming=False, pushNotifications=False, stateTransitionHistory=False), authentication=None, defaultInputModes=['text', 'text/plain'], defaultOutputModes=['text', 'text/plain'], skills=[AgentSkill(id='web_research_qa', name='Web Research and Answering', description='Answers questions using web search results when necessary.', tags=['research', 'qa', 'web search'], examples=['Who won the Nobel Prize in Physics 2024?', 'What is quantum computing?', 'Summarize the latest news about AI.'], inputModes=['text', 'text/plain'], outputModes=['text', 'text/plain'])]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payloads_and_agents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentCard(name='PocketFlow Research Agent (A2A Wrapped)', description='A simple research agent based on PocketFlow, made accessible via A2A.', url='http://localhost:10003/', provider=None, version='0.1.0-a2a', documentationUrl=None, capabilities=AgentCapabilities(streaming=False, pushNotifications=False, stateTransitionHistory=False), authentication=None, defaultInputModes=['text', 'text/plain'], defaultOutputModes=['text', 'text/plain'], skills=[AgentSkill(id='web_research_qa', name='Web Research and Answering', description='Answers questions using web search results when necessary.', tags=['research', 'qa', 'web search'], examples=['Who won the Nobel Prize in Physics 2024?', 'What is quantum computing?', 'Summarize the latest news about AI.'], inputModes=['text', 'text/plain'], outputModes=['text', 'text/plain'])])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared[\"agents_list\"][shared[\"selected_agent\"][0][\"selected_agent\"] - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n[]\\n```\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a user's question screener. Your duty is to select the agents that proper to answer user's question.\n",
      "\n",
      "The question: How is Thai stock market this week?\n",
      "\n",
      "These are agents who can you ask for consult:\n",
      "\n",
      "Available agents:\n",
      "\n",
      "Agent number 1:\n",
      "Name: PocketFlow Research Agent (A2A Wrapped)\n",
      "Description: A simple research agent based on PocketFlow, made accessible via A2A.\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "You may select one of them to help answer by return the array of selected agent number or if you find no one could help you, you may return empty array.\n",
      "Your answer will be passed directly to JSON so You must return your selected agent(s) with the following JSON fiedls\n",
      "[\n",
      "    {\n",
      "        \"selected_agent: <int, the number of agent that you choose to answer this question>,\n",
      "        \"question_to_answer\": <str, the question to ask the agent>\n",
      "    },\n",
      "    {/*...other agent you can select as much as you want*/}\n",
      "]\n",
      "\n",
      "Remember: Your answer will be passed directly to JSON parsing function, therefore return only the array of json and not include PREFIX, SUFFIX or Prologue\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    agent_selector_template.render(\n",
    "        question=\"How is Thai stock market this week?\",\n",
    "        available_agents_prompt=shared[\"available_agents_prompt\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'These are agents who can you ask for consult:\\n\\nAvailable agents:\\n\\nAgent number 1:\\nName: PocketFlow Research Agent (A2A Wrapped)\\nDescription: A simple research agent based on PocketFlow, made accessible via A2A.\\n--------------------------------\\n\\n\\nYou may select one of them to help answer by return the array of selected agent number or if you find no one could help you, you may return empty array.\\nYour answer will be passed directly to JSON so You must return your selected agent(s) with the following JSON fiedls\\n[\\n    {\\n        \"selected_agent: <int, the number of agent that you choose to answer this question>,\\n        \"question_to_answer\": <str, the question to ask the agent>\\n    },\\n    {/*...other agent you can select as much as you want*/}\\n]\\n\\nRemember: Your answer will be passed directly to JSON parsing function, therefore return only the array of json and not include PREFIX, SUFFIX or Prologue'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared[\"available_agents_prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grocery List:\n",
      "\n",
      "- Milk (2 liters)\n",
      "\n",
      "- Eggs (12 pcs)\n",
      "\n",
      "- Bread (1 loaf)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from jinja2 import Template\n",
    "\n",
    "# Main template string\n",
    "main_template = \"\"\"\n",
    "Grocery List:\n",
    "{% for item in items %}\n",
    "- {% include 'line_template' %}\n",
    "{% endfor %}\n",
    "\"\"\"\n",
    "\n",
    "# Sub-template string\n",
    "line_template = \"{{ item.name }} ({{ item.qty }})\"\n",
    "\n",
    "# Create a Jinja2 environment and manually load sub-templates\n",
    "from jinja2 import DictLoader, Environment\n",
    "\n",
    "# Setup with in-memory templates\n",
    "env = Environment(\n",
    "    loader=DictLoader({\"main_template\": main_template, \"line_template\": line_template})\n",
    ")\n",
    "\n",
    "# Load and render\n",
    "template = env.get_template(\"main_template\")\n",
    "\n",
    "# Sample data\n",
    "items = [\n",
    "    {\"name\": \"Milk\", \"qty\": \"2 liters\"},\n",
    "    {\"name\": \"Eggs\", \"qty\": \"12 pcs\"},\n",
    "    {\"name\": \"Bread\", \"qty\": \"1 loaf\"},\n",
    "]\n",
    "\n",
    "# Render\n",
    "output = template.render(items=items)\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
